---
title: Self-imposed limitations and data ethics
draft: false
---

We refuse to share the full access to the database to who ask us so, that assets represent the trust of our adopters and we pledge to protect it.

At the moment, the protection model is _by policy_, as part of our development roadmap, we want to gradually improve the technology and offer protected _by design_.

By installing fbTREX, we are asking individuals to share some of the data - not their personal data, but what Facebook gives them. The goal is to study how social media influences, not the subject participating.

Still, many Personally identifiable information, can be present in such informations.  Because the only goal of this data collection is the collective interest, transparency and fairness are two essential values. The project ethics define clearly which limits we give to yourself, in the collection and in the analysis. We don't have a business to develop, or a user profiling schema behind.

**First limitation**: we observe only the timelines, not individual profiles or pages. This is the difference between self assessment and enabling [social media intelligence](https://responsibledata.io/2016/12/12/social-media-intelligence-the-wayward-child-of-open-source-intelligence/), which could be an abusive practice and we do not want to enable that kind of practice carelessly. We consider timeline of public post something linked to your individual profile, therefore is for us a PII to protect.

**Second limitation**: we only store public posts on our server.

**Third limitation**: Users who install the extension have full control over their data; they can delete what they submit whenever they want.

**Fourth limitation**: Nobody has access to an individual’s data unless the owner grants them access.This means: users can opt-in to every possible third-party they might want to include or interact with.

**Fifth limitation**: if we, fbTREX, run analysis on the dataset, the analysis would be developed to understand the social phenomenon of information served up in an algorithmic timeline, not specific information about the individual profiles we are studying. This can’t be formally verified, therefore during the ALEX development we would like to formulate and publish updates on the safeguards we are implementing in that research.
